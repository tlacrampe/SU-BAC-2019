---
title: "NYC Energy Forecasting"
author: "Seattle University Business Analytics"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:

    code_folding: show
    highlight: tango
    theme: yeti
    toc: yes
    toc_depth: 5
    toc_float: yes
---
 
# loading in the libraries
```{r}
library(tidyverse)
library(skimr)            # useful for sumarizing information
library(lubridate) # useful for manipulating datetime information
```

# reading in the data

```{r}
LOAD = read.csv("LOAD.csv")
PRICE = read.csv("PRICE.csv")
WEATHER = read.csv("WEATHER.csv")
```

# summarizing the data

```{r}
skim(LOAD)
skim(PRICE)
skim(WEATHER)
```

No missing values for the LOAD dataset, PRICE dataset, and WEATHER dataset, which is good for us

# combining the load and price on the date/time attribute (may introduce NAs through left joining)

```{r}
leftDat = LOAD %>% 
  left_join(PRICE)
skim(leftDat)
```

left joining introduces 3828 missing values due to the difference between price and load date ranges, where price ranges from 11/1/2011 to 11/30/2018 while load ranges from 11/1/2011 to 12/15/2018. 

There is also a discrepency between the number of ZONES, where the PRICE datasheet has 11 ZONES when compared to LOAD which has 15 ZONES

# Using inner join

by using an inner join, we can preven the NAs by only focusing on shared keys across both dataframes, this will remove information regarding the additional dates (12/1/2018-12/15/2018) and the extra 4 zones that are not included in the PRICE datasheet

```{r}
innerDat = LOAD %>% 
  inner_join(PRICE)
skim(innerDat)
```

This dataset lacks the missing values of the previous one

# combinig the load variable with the various price components to get an aggregate value

```{r}
innerDat$LOAD = as.numeric(innerDat$LOAD)
leftDat$LOAD = as.numeric(leftDat$LOAD)

innerDat$TotalLMBP = innerDat$LOAD * innerDat$LMBP
leftDat$TotalLMBP = leftDat$LOAD * leftDat$LMBP

innerDat$CostCongestion = innerDat$LOAD * innerDat$MCC
leftDat$CostCongestion = leftDat$LOAD * leftDat$MCC

innerDat$CostLosses = innerDat$LOAD * innerDat$MCL
leftDat$CostLosses = leftDat$LOAD * leftDat$MCL

innerDat$TotalSystemEnergy = innerDat$TotalLMBP - innerDat$CostCongestion - innerDat$CostLosses
leftDat$TotalSystemEnergy = leftDat$TotalLMBP - leftDat$CostCongestion - leftDat$CostLosses

innerDat$SystemEnergyPrice = innerDat$TotalSystemEnergy / innerDat$LOAD
leftDat$SystemEnergyPrice = leftDat$TotalSystemEnergy / leftDat$LOAD
```

# Handling the weather data

in weather.csv we have two types of values, forecasted and actual. if VINTACE == Actual, then the data is the recorded observations for that day--otherwise the data is a forecast performed on the vintage day predicting weather conditions for the forecast_day. These forecasts/observations are made at each of the weather stations, and covers a range from march 1, 2011 to dec 16, 2018.

Let's split the weather into forecasts and actuals

```{r}
actuals = WEATHER %>% 
  filter(VINTAGE == 'Actual')
forecasts = WEATHER %>% 
  filter(VINTAGE == 'Forecast')
skim(actuals)
skim(forecasts)
```


Next let's begin assessing the accuracy of the forecasts

```{r}
actuals$FORECAST_DATE = NULL
actuals$VINTAGE = NULL
names(actuals)[3] = 'actual_MAX_TEMP'
names(actuals)[4] = 'actual_MIN_TEMP'
names(actuals)[5] = 'actual_MAX_WET_BULB'
names(actuals)[6] = 'actual_MIN_WET_BULB'

forecastsWithActuals = forecasts %>% 
  left_join(actuals, by = c('VINTAGE_DATE' = 'VINTAGE_DATE', 'STATION_ID' = 'STATION_ID'))

skim(forecastsWithActuals)

missingActuals = forecastsWithActuals %>% 
  filter(is.na(actual_MAX_TEMP))

forecastsWithActuals = na.omit(forecastsWithActuals) # removes the NA values

forecastsWithActuals$dateDif = mdy(forecastsWithActuals$VINTAGE_DATE) - mdy(forecastsWithActuals$FORECAST_DATE) # calculates days-out form forecast
skim(as.numeric(forecastsWithActuals$dateDif))

forecastsWithActuals$lowerDif = forecastsWithActuals$actual_MIN_TEMP - forecastsWithActuals$MIN_TEMP
skim(forecastsWithActuals$lowerDif)

forecastsWithActuals$upperDif = forecastsWithActuals$actual_MAX_TEMP - forecastsWithActuals$MAX_TEMP
skim(forecastsWithActuals$upperDif)
```

